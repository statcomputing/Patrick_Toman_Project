---
title: "Block Maxima Methods for Extreme Snowfall Events"
author: Patrick Toman^[<patrick.toman@uconn.edu>; Ph.D. student at Department of Statistics,
  University of Connecticut.]
date: "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
bibliography: citations.bib
bibliostyle: asa
link-citations: yes
documentclass: article
fontsize: 11pt
geometry: margin = 2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,message = F,fig.height = 5,fig.width = 4,fig.align = 'center',dpi = 300)
```

```{r,echo=FALSE,message=FALSE}
library(tidyverse)
library(lubridate)

data_dir <- "D:/Fall2020/StatComputing/Assignments/Patrick_Toman_Project/data/"

snowfall_df <- read_csv(paste0(data_dir,'final_snowfall_data.csv'))

snowfall_list <- split(snowfall_df,f = snowfall_df$name)

```

# Introduction 

In the first 9 months of 2020, there have been 16 extreme weather or climate related events with monetary losses exceeding $1 billion dollars in the united states, tying the annual records set by 2011 and 2017 @smith_2020. One of the most disruptive events, particularly for urbanized areas, are extreme snow events. One question at the forefront of researchers and planners minds is whether or not the frequency and intensity of extreme winter storms is increasing. To that end, @trend_return_levels proposed methods based on \textit{generalized extreme value distributions} for modeling trend and return levels for extreme snow events in New York City using 56 years of annual snowfall data. They found that their modeling framework was useful in modeling explaining extreme snow events in the city. Given Lee and Lee's report success, an obvious line of inquiry would be to assess if this model can be applied to a different geo-spatial location. With this in mind, this report takes the methods from Lee and Lee's paper and applied them to annual snowfall data for Chicago,Illinois, another city that is prone to crippling blizzards. 

# Data 

Daily snowfall data is downloaded from the @ncei_2020 using the Climate Online Data (CDO) tool. Three weather stations are selected from the Chicago Area: Midway, O'Hare, and Park Forest. Table \ref{tab: station_summaries}, gives a geographic description of the three stations. The last 61 years of daily snowfall data from each of the four station is used in the analysis, starting from the dates July 1st,1960 to June 30th, 2020. Daily snowfall is defined as the maximum amount of that has accumulated prior to melting or settling for the day. The snowfall data from NCEI is measured in inches with the amounts being rounded to the nearest tenth of an inch with amounts less than $0.1$ being recored as zeros. Furthermore, $\approx 8 \%$ of the days in our analysis have non-trace snow amounts, we call these \textit{snow events} in our analys. Since major snowfall events are tend to last multiple days, consecutive days with non-zero snowfall are merged to represent one single snow event in the data. In addition, snowfall observation refers to the accumulated snowfall associated with a given storm. Finally, a \textit{snow year} is defined as a one-year period that starts on July 1st to June 30th. For instance, the snow records from July 1st 2012 and June 30th, 2013 would correspond to the 2012 snow year. Note that there are missing observations in the data. For Midway, $< 0.8 \%$ of daily observations are missing, O'Hare is missing $\approx 0.9\%$ of observations and $\approx 8 \%$ are missing for Park Forest. Most of the missingness appears to be concentrated in non-winter months, therefore, the issue of missing data is negligible. 

\begin{table}[ht]
\centering
\caption{Station Summaries }
\label{tab: station_summaries}
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccccc}
\hline
Station & Full Station Name & Latitude & Longitude & Elevation \\ \hline
Chicago & CHICAGO MIDWAY AIRPORT 3 SW, IL US & 41.74 & -87.78 & 189.00 \\
Park Forest & PARK FOREST, IL US & 41.49 & -87.68 & 216.40 \\
O'Hare & CHICAGO OHARE INTERNATIONAL AIRPORT, IL US & 41.96 & -87.93 & 201.80 \\ \hline
\end{tabular}%
}
\end{table}

# Methods 

## Block Maxima Methods for GEV 

Let $X_1,\ldots,X_k$ be independent and identically distributed IID random variables that have the common CDF $F(.)$. Next, let us define $M^{(k)} = max\left\{X_1,\ldots,X_k\right\}$ as the maximum order statistic for a \textit{block} of $k$ these random variables. Suppose then that there are a set of constants $\{a_k\}$ and $\{b_k\}$ with $b_k > 0 \ \forall k$ so that scale $M^{(k)}$ such that 

\begin{equation}
  \label{eq: gev_thm}
  P\left(\frac{ M^{(k)} - a_k }{b_k} \le x \right) \to G(x) \ \text{for} \ k \to \infty
\end{equation}

where $G(.)$ is a non-degenerate distribution function. Then according to the Fisher-Tippett-Gnedenko theorem, $G(.)$ follows one of these distribution families: Gumbel,Frechet, or Weibull @trend_return_levels. Furthermore, these families can be further generalized using the \textit{generalized extreme value} (GEV) distribution function 

\begin{equation}
  \label{eq: gev_cdf}
  G(x) = exp\left\{- \left[1 + \xi(\frac{x - \mu}{\sigma})\right]_{+}^{\frac{-1}{\xi}}\right\}
\end{equation}

where $z_{+} = max\{z,0\}, \mu \in \mathcal{R},\sigma \in \mathcal{R}^{+}, \ \text{and} \ \xi \in \mathcal{R}^{+}$. In application settings, block maxima methods rely on a sequence of of maximum order statistics from a CDF $F(.)$. If the block sizes are large enough, then the GEV theorem states that  In our case, each snow year is treat as a block and then we extract the maximum snowfall statistic from each snowfall year for each station as our extreme event for that year. 

## Maximum Likelihood for GEV Models

Assume that we have $\xi \ne 0$. If $X_1,\ldots,X_N \overset{iid}{\sim} GEV(\Theta)$ where $\Theta = (\mu,\sigma,\xi), -\infty < \mu,\xi < \infty, \sigma >0$ is our vector of unknown parameters. then we have the log-likelihood for for $\mathbf{X} = \left\{X_1,\ldots,X_N\right\}$ as

\begin{equation}
  \label{eq: gev_ll}
  ln\left(\Theta|\mathbf{X}\right)  = -Nln(\sigma) + \left(\frac{1}{\xi}+1\right)\sum_{i=1}^{N}\left(1 \xi\left(\frac{x_i - \mu}{\sigma}\right)\right) - \sum_{i=1}^{N}\left(1 + \xi\left(\frac{x_i - \mu}{\sigma}\right)\right)
\end{equation}

assuming that $1 + \xi\left(\frac{x_i - \mu}{\sigma}\right) > 0$. Further information can be found in @statistics_of_extremes. Indeed, parameter estimates can be obtained by numerical estimation methods such as Newton-Raphson. Expressions for the gradient can be found the appendix \textcolor{red}{possibly remove}.  In this project, we use the standard \textit{optim()} or \textit{nlme()} function found in the R programming language.

## Return Levels 

Some of the most important quantities in any extreme values analysis are the return levels. The return level for an associated return period of $K$ years is the expected level that is to be exceeded on average once over the following $K$ years. In the case of annual maximums we have the return level $X_k$ for a period of $K$ years defined as

\begin{equation}
  \label{eq: gev_return}
    X_k = \begin{cases}
            \mu - \frac{\sigma}{\xi}\left[1 - \{ - ln(1-K^{-1})\}^{-\xi}\right] \ \text{if} \ \xi \ne 0 \\
            \mu - \sigma\left[- ln(1-K^{-1})\right] \ \text{if} \ \xi = 0 \\
          \end{cases}
\end{equation}

Invoking the invariance property of MLEs, we can solve for the MLE of the return level $\hat{X}_k$ by simply substituting the MLEs for $(\mu,\sigma,\xi)$ attained through Newton-Raphson. 

## Smith's Method for Spatial and Temporal Dependence

Snowfall data collected from stations close in proximity to one another will inevtiably exhibit spatial correlation. To account for this spatial correlation in our standard errors, we can employ a method devised by Smith @smith_1990 where MLE estimates are attained under the standard IID assumption and then standard errors are corrected in a post-hoc fashion to account for spatial dependence. \textcolor{red}{More information about this method can be found in the appendix}. Furthermore, for block maxima methods, temporal dependence is typically not an issue since annual maxima tend to be separated by a large gap of time. To confirm this,we calculate the ACF of the annual maxima series for each station and find that there is no statistically significant auto-correlation for the $\alpha = 0.05$ level. 

```{r,fig.height = 3,fig.width = 8}
par(mfrow = c(1,3))
plot(acf(snowfall_list$Midway$ann_max_snowf,plot = F),main = 'ACF - Midway')
plot(acf(snowfall_list$Ohare$ann_max_snowf,plot = F),main = "ACF - O'Hare")
plot(acf(snowfall_list$ParkForest$ann_max_snowf,plot = F),main = 'ACF - Park Forest')

```

## Bootstrap CI for Return Levels 

For GEV models, @Rust2011 note that asymptotic standard errors attained via the delta method are often inadequate in estimating the sampling variability of MLE estimators for return levels.  @trend_return_levels propose bootstrapping the confidence intervals for return levels using the standard percentile method where we use the $\alpha/2$ upper and lower quantiles of the bootstrapped return level estimates. Because the distribution of return levels tends to exhibit right-skew, therefore, standard bootstrap methods  will be biased. To remedy this bias in bootstrap return level estimates, we can employ the \textit{bias corrected and accelerated} (BCa) bootstrap methods introduced by @efron_1979. Suppose that we wish to generate $B$ bootsrap estimates of return level $X_k$. The BCa method works by first calculating the bias correction estimate $z_{BC}$

\begin{equation}
  \label{eq: zbc}
    z_bc = \Phi^{-1}\left(\frac{1}{B}\sum_{b = 1}^{B}I\left(\hat{x}^{(b)}_K < \hat{x}_K\right)\right)
\end{equation}

where $\Phi(.)$ is the standard normal CDF, $I(.)$ is the indicator function, and $\hat{x}_k$ denotes the MLE of the return level for period $K$ using the original data. Next, we calculate the acceleration constant $c_A$ which is defined as 

\begin{equation}
  \label{eq: acceleration}
  c_A = \frac{\sum_{t=1}^{n}\left(\tilde{x}^{-t}_K - \tilde{x}_K\right)^3}{6\left[\sum_{t=1}^{n}\left(\tilde{x}^{(-t)}_{K} - \tilde{x}_K\right)^2\right]^{3/2}}
\end{equation}

where $\tilde{x}^{(-t)}_{K}$ denotes the delete-1 jacknife estimate of $x_K$ where we have deleted the $t^{th}$ observation from the dataset and $\tilde{x}^{(-t)}_K = \sum_{t=1}^{n}\tilde{x}^{(-t)}_{K}$. Further information can be found in @givens_hoeting_2013. Thus, the $(1-\alpha)*100\%$ BCa is interval has the following quantiles as its upper (lower) endpoints given by

\begin{equation}
  \label{eq: bca_quantiles}
    \Phi\left(z_{BC} + \frac{z_{BC} \pm z_{\alpha/2}}{1 - c_A(z_{BC}\pm z_{\alpha_2})}\right)
\end{equation}

# Implementation and Results

Using the notation from @trend_return_levels, let $N_{s}$ denote the number of snowstorms that occured at station $s$ during the study period from July 1st, 1960 to June 30th, 2020. If we let $\mathbf{X} = \left\{X_{s,1},\ldots,X_{s,N_s}\right\}$ represent the the accumulated snowfall observed at station $s$ where $X_{s,j}, \ j \in {1,\ldots,N_S}$ denotes the accumulated snowfall for snowstorm $j$ during the study period. Next, if we denote $M_{s,t}$ denote the maximum for each snow year $t \in \{1960,\ldots,2020\}$, then we have $M_{s,t} \sim GEV(\mu_s,\sigma_s,\xi_s)$.  Using the block maxima methods described in the [Methods] section, we fit several different models and compare them using Akaike's Corrected Information Criterion (AICc) where $AICc = 2\left( p - \ell(\hat{\Theta}) + \frac{p(p+1)}{n - p+1}\right)$ where $p$ is the number of parameters, $\ell(\hat{\Theta})$ denotes the value of the log-likelihood evaluated at the MLE, and $n$ is the number of observations. Models with smaller AICc are preferred. In addition, we calculate $100\cdot(1-\alpha)\% , \alpha = 0.05$ CI BCa intervals for return levels $X_k, K = \left\{25,50,75,100\right\}$ using $B = 10000$ replications for all six reduced models mentioned in table \ref{eq: gev_parameter_estimates}. 

## Models

Initially, we build a full model in which we assume that each station has its own location, shape, and scale parameters. In other words, we have $\Theta_s = (\mu_s,\sigma_s,\xi_s), s = 1,2,3$.  The AICc of this model is $-884.1794$. Next, we build a model where $\mu_s$ is fit individually for each station but $\sigma$ and $\xi$ are assumed to be the same for all three locations. For the reduced model, we find that the AICc is $-895.6098$. Therefore, we prefer the reduced model where $\mu_s$'s are assumed to be different for the stations but $\sigma$ and $\xi$ are assumed common. 

Having established that $\sigma$ and $\xi$ should be common to all three stations, three different stationary models, one with a distinct $\mu_s$ for all three locations, the second where we merge the two closest $\mu_s$'s from the first model, and then a final model where $\mu_s$ is assumed to be the same across all three equations. In all three cases, maximum likelihood estimates are obtained using Newton-Raphson via the \textit{nlme()} function in R. Naive standard errors are obtained for these models by inverting the hessian returned from \textit{nlme()}. To account for spatial correlation in the standard errors, we implement Smith's method. Indeed, we find that the corrected standard errors are larger than the naive standard errors, indicating that there is some measure of spatial correlation in the annual maxima series as anticipated. Observe that the estimates for $\xi$ are quite small relative to their standard error with the largest $\frac{\hat{\xi}}{se(\hat{\xi})} \approx 1$, thus, it is likely reasonable to conclude that $\xi$ is not statistically different from zero. More details can be found in table \ref{tab: gev_parameter_estimates}. 

Next, because of the possibility of a a linear trend in the data, a set of non-stationary models are fit following the same structure as the stationary models except we now model the location parameters $\mu_s$ as a function of time. Following the example of @trend_return_levels, we have 

\begin{equation}
  \label{eq: gev_trend}
  \mu_{s,t} = \mu_s + \beta\left(\frac{t - 1960}{10}\right), \ t = 1960,\ldots,2020
\end{equation}

where $\beta$ is a trend parameter that captures the expected in maximum snowfall over a decade. It is assumeth that trend is the same for all three stations in our analysis. The non-stationary parameter estimates are quite similar to the stationary estimates. In addition, we find that the trend paramter $\beta$ is not statistically different from zero at the $\alpha = 0.05$ level, thus, we can reasonably conclude that there is not a long-term trend in the maximum snowfall for Chicago in this time frame. Once again, more details are given in table \ref{tab: gev_parameter_estimates}.


\begin{table}[ht]
\centering
\caption{GEV Estimates W/ Standard Errors in Parentheses (left: Uncorrected, right: Corrected)}
\label{tab: gev_parameter_estimates}
\resizebox{\textwidth}{!}{
\begin{tabular}{c|ccc|ccc|}
\cline{2-7}
\multicolumn{1}{l|}{} & \multicolumn{3}{c|}{Stationary Models} & \multicolumn{3}{c|}{Non-Stationary Models} \\ \cline{2-7} 
 & \multicolumn{1}{c|}{Model 1} & \multicolumn{1}{c|}{Model 2} & Model 3 & \multicolumn{1}{c|}{Model 1} & \multicolumn{1}{c|}{Model 2} & Model 3 \\ \hline
\multicolumn{1}{|c|}{$\mu_{M}$} & \multicolumn{1}{c|}{6.150 (0.308,0.330)} & \multicolumn{1}{c|}{6.152 (0.309,0.639)} & 5.367 (0.201,0.246) & \multicolumn{1}{c|}{6.116 (0.462,0.498)} & \multicolumn{1}{c|}{6.079 (0.463,0.734)} & 5.214 (0.389,0.462) \\ \hline
\multicolumn{1}{|c|}{$\mu_{O}$} & \multicolumn{1}{c|}{5.242 (0.321,0.370)} & \multicolumn{1}{c|}{4.978 (0.234,0.272)} & 5.367 (0.201,0.246) & \multicolumn{1}{c|}{5.210 (0.457,0.484)} & \multicolumn{1}{c|}{4.914 (0.389,0.598)} & 5.214 (0.389,0.462) \\ \hline
\multicolumn{1}{|c|}{$\mu_{PF}$} & \multicolumn{1}{c|}{4.743 (0.311,0.337)} & \multicolumn{1}{c|}{4.978 (0.234,0.272)} & 5.367 (0.201,0.246) & \multicolumn{1}{c|}{4.716 (0.421,0.538)} & \multicolumn{1}{c|}{4.914 (0.389,0.598)} & 5.214 (0.389,0.462) \\ \hline
\multicolumn{1}{|c|}{$\beta$} & N/A & N/A & N/A & 0.01 (0.102,0.128) & 0.022 (0.101,0.154) & 0.048 (0.105,0.133) \\
\multicolumn{1}{|c|}{$\sigma$} & 2.392 (0.141, 0.224) & 2.398 (0.141,0.293) & 2.485 (0.142,0.241) & 2.392 (0.141,0.224) & 2.397 (0.141,0.295) & 2.481 (0.144,0.238) \\
\multicolumn{1}{|c|}{$\xi$} & 0.045 (0.046, 0.056) & 0.046 (0.046,0.087) & 0.028 (0.044,0.056) & 0.045 (0.461,0.056) & 0.048 (0.046,0.088) & 0.030 (0.044,0.056) \\
\multicolumn{1}{|c|}{$\ell$} & 452.974 & 453.663 & 458.117 & 452.980 & 453.640 & 458.013 \\
\multicolumn{1}{|c|}{$AICc$} & -895.609 & -899.101 & -910.101 & -893.462 & -896.942 & -907.800 \\ \hline
\end{tabular}
}
\end{table}

## Bootstrap Return Levels

We present BCa return levels for both the stationary and non-stationary versions model 1. Model 1 is chosen since there are not substantial differences in the AICc values for the models, however, there does seem to be some differences in the location the location parameters that are worth exploring. Using figures \textcolor{red}{cite figures}, we can draw several inferences, First, we observe that the 95\% CI is fairly similar for both models though it is a bit wider for the trend model. This helps to corroborate our findings that the trend parameter $\beta$ is not statistically different from 0, thus, indicating that there is no long term trend in the annual maximum snowfall. Furthermore, the CI plots indicate that we can expect a snowstorm that dumps $\approx 15$ inches of snow to occurs once every 50 years or so in the chicago area. Finally, we observe that the return median return levels for all periods are higher for Midway than for the other two sites. 


# Conclusions and Further Work

# References
